 ## Abstract
 
 This project demonstrates a data engineering pipeline showcasing the interaction between various data processing technologies within a containerized environment. Using Docker and docker-compose, the system deploys multiple components: three drone simulators and one central tower, all implemented in Python. Drones continuously generate coordinate data, which is transmitted via Apache Kafka topics. The tower component consumes these Kafka streams, performs an initial transformation by amending the incoming dataframes, and persists the processed coordinates into a PostgreSQL database. Further data transformation can occurs within PostgreSQL through the use of a database view. Finally, a Grafana instance connects to the PostgreSQL database to visualize the drone movements and status, applying a final transformation by displaying only the latest N coordinate points for monitoring purposes. This setup provides a practical example of stream processing, data storage, and real-time visualization using common industry tools.
